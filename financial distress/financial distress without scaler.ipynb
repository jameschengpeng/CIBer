{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/shebrahimi/financial-distress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOT Apply MinMaxScaler, use all data to do 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r7user5/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(1, '/home/r7user5/Desktop/STAT')\n",
    "import comonotonic as cm\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import copy\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import ensemble_ciber as ec\n",
    "import conditional_ciber as cc\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Financial Distress.csv\")\n",
    "df['Financial Distress'].values[df['Financial Distress'].values > -0.5] = 0\n",
    "df['Financial Distress'].values[df['Financial Distress'].values <= -0.5] = 1\n",
    "df['x80'] = df['x80']-1\n",
    "df['Financial Distress'] = df['Financial Distress'].astype(int)\n",
    "distress = df['Financial Distress']\n",
    "df = df.drop(columns=['Company','Time','Financial Distress'])\n",
    "df['Financial Distress'] = distress\n",
    "colnames = [('X'+str(i)) for i in range(df.shape[1]-1)]\n",
    "colnames.append('Y')\n",
    "df.columns = colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [79]\n",
    "cont_col = [i for i in range(79)]+[i for i in range(80,83)]\n",
    "discrete_feature_val = {79:37}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = utils.outlier_removal(df, cont_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = reduced_df.iloc[:,:-1].to_numpy()\n",
    "y = reduced_df.iloc[:,-1].to_numpy()\n",
    "smote_nc = SMOTENC(categorical_features=[79], random_state=0)\n",
    "x_resample, y_resample = smote_nc.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits = 5, shuffle = True)\n",
    "ciber_record = list()\n",
    "ada_record = list()\n",
    "rf_record = list()\n",
    "xgb_record = list()\n",
    "lgb_record = list()\n",
    "DT_record = list()\n",
    "svm_record = list()\n",
    "lr_record = list()\n",
    "nb_record = list()\n",
    "gaussian_nb_record = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r7user5/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/r7user5/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/r7user5/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r7user5/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/r7user5/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/r7user5/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r7user5/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/r7user5/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/r7user5/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r7user5/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/r7user5/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/r7user5/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r7user5/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/r7user5/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/r7user5/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "itr = 1\n",
    "for train_idx, test_idx in k_fold.split(x_resample):\n",
    "    x_train, x_test = x_resample[train_idx,:], x_resample[test_idx,:]\n",
    "    y_train, y_test = y_resample[train_idx], y_resample[test_idx]\n",
    "    # ciber\n",
    "    ciber = cm.clustered_comonotonic(x_train,y_train,discrete_feature_val,cont_col,\n",
    "                                     categorical, 0.98, None, corrtype='mutual_info',\n",
    "                                     discrete_method='mdlp')\n",
    "    ciber.run()\n",
    "    ciber_predict = ciber.predict(x_test)\n",
    "    ciber_record.append(accuracy_score(y_test, ciber_predict))\n",
    "    #  adaboost\n",
    "    ada_clf = AdaBoostClassifier()\n",
    "    ada_clf.fit(x_train,y_train)\n",
    "    ada_predict = ada_clf.predict(x_test)\n",
    "    ada_record.append(accuracy_score(y_test, ada_predict))\n",
    "    # random forest\n",
    "    rf_clf = RandomForestClassifier()\n",
    "    rf_clf.fit(x_train,y_train)\n",
    "    rf_predict = rf_clf.predict(x_test)\n",
    "    rf_record.append(accuracy_score(y_test, rf_predict))\n",
    "    # xgboost\n",
    "    xgb_clf = xgb.XGBClassifier()\n",
    "    xgb_clf.fit(x_train,y_train)\n",
    "    xgb_predict = xgb_clf.predict(x_test)\n",
    "    xgb_record.append(accuracy_score(y_test, xgb_predict))\n",
    "    # light GBM\n",
    "    lgb_clf = lgb.LGBMClassifier()\n",
    "    lgb_clf.fit(x_train, y_train)\n",
    "    lgb_predict = lgb_clf.predict(x_test)\n",
    "    lgb_predict = lgb_predict.round(0).astype('int')\n",
    "    lgb_record.append(accuracy_score(y_test, lgb_predict))\n",
    "    # decision tree\n",
    "    DT_clf = tree.DecisionTreeClassifier()\n",
    "    DT_clf.fit(x_train, y_train)\n",
    "    DT_predict = DT_clf.predict(x_test)\n",
    "    DT_record.append(accuracy_score(y_test, DT_predict))\n",
    "    # svm\n",
    "    svm = SVC()\n",
    "    svm.fit(x_train, y_train)\n",
    "    svm_predict = svm.predict(x_test)\n",
    "    svm_record.append(accuracy_score(y_test, svm_predict))\n",
    "    # logistic regression\n",
    "    lr_clf = LogisticRegression()\n",
    "    lr_clf.fit(x_train, y_train)\n",
    "    lr_predict = lr_clf.predict(x_test)\n",
    "    lr_record.append(accuracy_score(y_test, lr_predict))\n",
    "    # nb by ciber\n",
    "    nb_clf = cm.clustered_comonotonic(x_train,y_train,discrete_feature_val,cont_col,\n",
    "                                    categorical, 1, None, corrtype='spearman',\n",
    "                                    discrete_method='mdlp')\n",
    "    nb_clf.run()\n",
    "    nb_predict = nb_clf.predict(x_test)\n",
    "    nb_record.append(accuracy_score(y_test, nb_predict))\n",
    "    # gaussian nb\n",
    "    gaussian_nb = GaussianNB()\n",
    "    gaussian_nb.fit(x_train, y_train)\n",
    "    gaussian_predict = gaussian_nb.predict(x_test)\n",
    "    gaussian_nb_record.append(accuracy_score(y_test, gaussian_predict))\n",
    "    \n",
    "    print(itr)\n",
    "    itr += 1\n",
    "    del x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = dict()\n",
    "record['ciber'] = ciber_record\n",
    "record['adaboost'] = ada_record\n",
    "record['random forest'] = rf_record\n",
    "record['xgboost'] = xgb_record\n",
    "record['light GBM'] = lgb_record\n",
    "record['decision tree'] = DT_record\n",
    "record['svm'] = svm_record\n",
    "record['logistic regress'] = lr_record\n",
    "record['ciber nb'] = nb_record\n",
    "record['gaussian nb'] = gaussian_nb_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = xlsxwriter.Workbook('5-fold CV without scaler.xlsx') \n",
    "worksheet = workbook.add_worksheet() \n",
    "row = 0\n",
    "for method in record.keys():\n",
    "    column = 1\n",
    "    worksheet.write(row, 0, method)\n",
    "    for acc in record[method]:\n",
    "        worksheet.write(row, column, acc)\n",
    "        column += 1\n",
    "    row += 1\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x_resample,y_resample,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an unsuccessful bagging\n",
    "# ciber = ec.bagging_ciber(n_estimators = 5, max_workers = 10)\n",
    "# ciber.fit(x_train,y_train,discrete_feature_val,cont_col,categorical,0.8,None)\n",
    "# prediction = ciber.predict(x_test)\n",
    "# print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       691\n",
      "           1       0.99      0.94      0.97       704\n",
      "\n",
      "    accuracy                           0.97      1395\n",
      "   macro avg       0.97      0.97      0.97      1395\n",
      "weighted avg       0.97      0.97      0.97      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c_como_demo = cm.clustered_comonotonic(x_train,y_train,discrete_feature_val,cont_col,\n",
    "                                      categorical, 0.98, None, corrtype='mutual_info',\n",
    "                                      discrete_method='mdlp')\n",
    "c_como_demo.run()\n",
    "c_como_predict = c_como_demo.predict(x_test)\n",
    "print(classification_report(y_test,c_como_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20181263786425277"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_como_demo.cross_entropy_loss(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       691\n",
      "           1       0.98      1.00      0.99       704\n",
      "\n",
      "    accuracy                           0.99      1395\n",
      "   macro avg       0.99      0.99      0.99      1395\n",
      "weighted avg       0.99      0.99      0.99      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier()\n",
    "xgb_clf.fit(x_train,y_train)\n",
    "xgb_predict = xgb_clf.predict(x_test)\n",
    "print(classification_report(y_test, xgb_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09233894895789105\n"
     ]
    }
   ],
   "source": [
    "xgb_proba = xgb_clf.predict_proba(x_test)\n",
    "print(utils.cross_entropy(xgb_proba, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r7user5/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       691\n",
      "           1       0.97      1.00      0.98       704\n",
      "\n",
      "    accuracy                           0.98      1395\n",
      "   macro avg       0.98      0.98      0.98      1395\n",
      "weighted avg       0.98      0.98      0.98      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(x_train,y_train)\n",
    "rf_predict = rf_clf.predict(x_test)\n",
    "print(classification_report(y_test, rf_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12500483664301854\n"
     ]
    }
   ],
   "source": [
    "rf_proba = rf_clf.predict_proba(x_test)\n",
    "print(utils.cross_entropy(rf_proba, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       691\n",
      "           1       0.94      0.98      0.96       704\n",
      "\n",
      "    accuracy                           0.96      1395\n",
      "   macro avg       0.96      0.96      0.96      1395\n",
      "weighted avg       0.96      0.96      0.96      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier()\n",
    "ada_clf.fit(x_train,y_train)\n",
    "ada_predict = ada_clf.predict(x_test)\n",
    "print(classification_report(y_test, ada_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8413441349424778\n"
     ]
    }
   ],
   "source": [
    "ada_proba = ada_clf.predict_proba(x_test)\n",
    "print(utils.cross_entropy(ada_proba, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       691\n",
      "           1       0.98      1.00      0.99       704\n",
      "\n",
      "    accuracy                           0.99      1395\n",
      "   macro avg       0.99      0.99      0.99      1395\n",
      "weighted avg       0.99      0.99      0.99      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = lgb.LGBMClassifier()\n",
    "lgb_clf.fit(x_train, y_train)\n",
    "lgb_predict = lgb_clf.predict(x_test)\n",
    "lgb_predict = lgb_predict.round(0).astype('int')\n",
    "print(classification_report(y_test, lgb_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0777683570831202\n"
     ]
    }
   ],
   "source": [
    "lgb_proba = lgb_clf.predict_proba(x_test)\n",
    "print(utils.cross_entropy(lgb_proba, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r7user5/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.74       691\n",
      "           1       1.00      0.30      0.46       704\n",
      "\n",
      "    accuracy                           0.65      1395\n",
      "   macro avg       0.79      0.65      0.60      1395\n",
      "weighted avg       0.79      0.65      0.60      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(x_train, y_train)\n",
    "svm_predict = svm.predict(x_test)\n",
    "print(classification_report(y_test, svm_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r7user5/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79       691\n",
      "           1       0.78      0.87      0.82       704\n",
      "\n",
      "    accuracy                           0.81      1395\n",
      "   macro avg       0.81      0.81      0.81      1395\n",
      "weighted avg       0.81      0.81      0.81      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(x_train, y_train)\n",
    "lr_predict = lr_clf.predict(x_test)\n",
    "print(classification_report(y_test, lr_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       691\n",
      "           1       0.93      0.98      0.95       704\n",
      "\n",
      "    accuracy                           0.95      1395\n",
      "   macro avg       0.95      0.95      0.95      1395\n",
      "weighted avg       0.95      0.95      0.95      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_clf = cm.clustered_comonotonic(x_train,y_train,discrete_feature_val,cont_col,\n",
    "                                categorical, 1, None, corrtype='spearman',\n",
    "                                discrete_method='mdlp')\n",
    "nb_clf.run()\n",
    "nb_predict = nb_clf.predict(x_test)\n",
    "print(classification_report(y_test,nb_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.16      0.27       691\n",
      "           1       0.54      0.98      0.70       704\n",
      "\n",
      "    accuracy                           0.57      1395\n",
      "   macro avg       0.72      0.57      0.49      1395\n",
      "weighted avg       0.71      0.57      0.49      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian_nb = GaussianNB()\n",
    "gaussian_nb.fit(x_train, y_train)\n",
    "gaussian_predict = gaussian_nb.predict(x_test)\n",
    "print(classification_report(y_test, gaussian_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
